{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark II - Dataframes and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T07:29:05.335514Z",
     "start_time": "2022-11-26T07:29:05.327050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/01/04 10:24:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Spark SQL Course\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T13:26:29.707124Z",
     "start_time": "2020-02-04T13:26:29.703404Z"
    }
   },
   "source": [
    "# `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:10.542875Z",
     "start_time": "2022-11-26T05:56:10.531942Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "row1 = Row(name=\"John\", age=21)\n",
    "row2 = Row(name=\"James\", age=32)\n",
    "row3 = Row(name=\"Jane\", age=18)\n",
    "row1['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:24.857874Z",
     "start_time": "2022-11-26T05:56:24.806632Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([row1, row2, row3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(name='John', age=21), Row(name='James', age=32), Row(name='Jane', age=18)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:25.579042Z",
     "start_time": "2022-11-26T05:56:25.571707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:27.694750Z",
     "start_time": "2022-11-26T05:56:26.310055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| John| 21|\n",
      "|James| 32|\n",
      "| Jane| 18|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:28.671432Z",
     "start_time": "2022-11-26T05:56:28.639892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8) MapPartitionsRDD[12] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[11] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  SQLExecutionRDD[10] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[9] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[4] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[3] at map at SerDeUtil.scala:69 []\n",
      " |  MapPartitionsRDD[2] at mapPartitions at SerDeUtil.scala:117 []\n",
      " |  PythonRDD[1] at RDD at PythonRDD.scala:53 []\n",
      " |  ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:289 []\n"
     ]
    }
   ],
   "source": [
    "print(df.rdd.toDebugString().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:31.842753Z",
     "start_time": "2022-11-26T05:56:31.833146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:55:33.939023Z",
     "start_time": "2022-11-26T05:55:33.388845Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 21|  male|\n",
      "| James| 25|female|\n",
      "|Albert| 46|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "rows = [\n",
    "    Row(name=\"John\", age=21, gender=\"male\"),\n",
    "    Row(name=\"James\", age=25, gender=\"female\"),\n",
    "    Row(name=\"Albert\", age=46, gender=\"male\")\n",
    "]\n",
    "df = spark.createDataFrame(rows)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:55:38.708168Z",
     "start_time": "2022-11-26T05:55:38.295622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 21|  male|\n",
      "| James| 25|female|\n",
      "|Albert| 46|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "column_names = [\"name\", \"age\", \"gender\"]\n",
    "rows = [\n",
    "    [\"John\", 21, \"male\"],\n",
    "    [\"James\", 25, \"female\"],\n",
    "    [\"Albert\", 46, \"male\"]\n",
    "]\n",
    "df = spark.createDataFrame(rows, column_names)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:19.074335Z",
     "start_time": "2022-01-26T10:58:19.068088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:37:24.358575Z",
     "start_time": "2022-11-26T06:37:16.489467Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 21|  male|\n",
      "| James| 25|female|\n",
      "|Albert| 46|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"name\", \"age\", \"gender\"]\n",
    "rdd = sc.parallelize([\n",
    "    (\"John\", 21, \"male\"),\n",
    "    (\"James\", 25, \"female\"),\n",
    "    (\"Albert\", 46, \"male\")\n",
    "])\n",
    "df = spark.createDataFrame(rdd, column_names)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe to rdd and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:37:41.958143Z",
     "start_time": "2022-11-26T06:37:41.952273Z"
    }
   },
   "outputs": [],
   "source": [
    "rdd2 = df.rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:42:38.623506Z",
     "start_time": "2022-11-26T06:42:38.617300Z"
    }
   },
   "outputs": [],
   "source": [
    "rdd3 = rdd2.map(lambda x: [x[0],x[1]+10,x[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:42:39.959294Z",
     "start_time": "2022-11-26T06:42:39.391647Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df = rdd3.toDF([\"name\",\"age\",\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:42:46.156497Z",
     "start_time": "2022-11-26T06:42:45.826816Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 31|  male|\n",
      "| James| 35|female|\n",
      "|Albert| 56|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:19.850578Z",
     "start_time": "2022-01-26T10:58:19.843835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('name', StringType(), True), StructField('age', LongType(), True), StructField('gender', StringType(), True)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:43:16.125207Z",
     "start_time": "2022-11-26T06:43:16.101139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:19.860631Z",
     "start_time": "2022-01-26T10:58:19.854012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:20.199419Z",
     "start_time": "2022-01-26T10:58:19.863528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "rows = [(\"John\", 21, \"male\")]\n",
    "df = spark.createDataFrame(rows, schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:20.882311Z",
     "start_time": "2022-01-26T10:58:20.201993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|John| 21|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"name\", \"age\", \"gender\"]\n",
    "rows = [\n",
    "    [\"John\", 21, \"male\"],\n",
    "    [\"Jane\", 25, \"female\"]\n",
    "]\n",
    "df = spark.createDataFrame(rows, column_names)\n",
    "\n",
    "# Create a temporary view from the DataFrame\n",
    "df.createOrReplaceTempView(\"new_view\")\n",
    "\n",
    "# Apply the query\n",
    "query = \"SELECT name, age FROM new_view WHERE gender='male'\"\n",
    "men_df = spark.sql(query)\n",
    "men_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SELECT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:21.162623Z",
     "start_time": "2022-01-26T10:58:20.884802Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|John| 21|\n",
      "|Jane| 25|\n",
      "+----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT name, age FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:21.388097Z",
     "start_time": "2022-01-26T10:58:21.164840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|John| 21|\n",
      "|Jane| 25|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\", \"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `WHERE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:21.704402Z",
     "start_time": "2022-01-26T10:58:21.402155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT * FROM table WHERE age > 21\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:21.924501Z",
     "start_time": "2022-01-26T10:58:21.706741Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.where(\"age > 21\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:22.377417Z",
     "start_time": "2022-01-26T10:58:21.926708Z"
    }
   },
   "source": [
    "# Alternatively:\n",
    "df.where(df['age'] > 21).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:22.566385Z",
     "start_time": "2022-01-26T10:58:22.380036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.age > 21).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:22.837136Z",
     "start_time": "2022-01-26T10:58:22.569324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").where(\"age > 21\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LIMIT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:23.315363Z",
     "start_time": "2022-01-26T10:58:22.842106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT * FROM table LIMIT 1\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:23.522646Z",
     "start_time": "2022-01-26T10:58:23.318694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:23.778517Z",
     "start_time": "2022-01-26T10:58:23.525281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ORDER BY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:24.190838Z",
     "start_time": "2022-01-26T10:58:23.781166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT * FROM table ORDER BY name ASC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:24.368069Z",
     "start_time": "2022-01-26T10:58:24.193899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df.name.asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ALIAS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:24.643668Z",
     "start_time": "2022-01-26T10:58:24.370758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|   sex|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT name, age, gender AS sex FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:24.858104Z",
     "start_time": "2022-01-26T10:58:24.646119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|   sex|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, df.age, df.gender.alias('sex')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CAST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:25.072286Z",
     "start_time": "2022-01-26T10:58:24.860474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|age_f|\n",
      "+----+-----+\n",
      "|John| 21.0|\n",
      "|Jane| 25.0|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT name, cast(age AS float) AS age_f FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:25.384433Z",
     "start_time": "2022-01-26T10:58:25.074523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|age_f|\n",
      "+----+-----+\n",
      "|John| 21.0|\n",
      "|Jane| 25.0|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, df.age.cast(\"float\").alias(\"age_f\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:25.648155Z",
     "start_time": "2022-01-26T10:58:25.386952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|age_f|\n",
      "+----+-----+\n",
      "|John| 21.0|\n",
      "|Jane| 25.0|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_age_col = df.age.cast(\"float\").alias(\"age_f\")\n",
    "df.select(df.name, new_age_col).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:25.931495Z",
     "start_time": "2022-01-26T10:58:25.651283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+----------+\n",
      "|name|age|gender|age_months|\n",
      "+----+---+------+----------+\n",
      "|John| 21|  male|       252|\n",
      "|Jane| 25|female|       300|\n",
      "+----+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT *, 12*age AS age_months FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:26.195480Z",
     "start_time": "2022-01-26T10:58:25.933620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+----------+\n",
      "|name|age|gender|age_months|\n",
      "+----+---+------+----------+\n",
      "|John| 21|  male|       252|\n",
      "|Jane| 25|female|       300|\n",
      "+----+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"age_months\", df.age * 12).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:26.422122Z",
     "start_time": "2022-01-26T10:58:26.197759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+----------+\n",
      "|name|age|gender|age_months|\n",
      "+----+---+------+----------+\n",
      "|John| 21|  male|       252|\n",
      "|Jane| 25|female|       300|\n",
      "+----+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\", (df.age * 12).alias(\"age_months\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric functions examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:26.748718Z",
     "start_time": "2022-01-26T10:58:26.425451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+-----+----+\n",
      "|  brand|cost|round|floor|ceil|\n",
      "+-------+----+-----+-----+----+\n",
      "|garnier|3.49|  3.5|    3|   4|\n",
      "| elseve|2.71|  2.7|    2|   3|\n",
      "+-------+----+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "columns = [\"brand\", \"cost\"]\n",
    "df = spark.createDataFrame([\n",
    "    (\"garnier\", 3.49),\n",
    "    (\"elseve\", 2.71)\n",
    "], columns)\n",
    "\n",
    "round_cost = fn.round(df.cost, 1)\n",
    "floor_cost = fn.floor(df.cost)\n",
    "ceil_cost = fn.ceil(df.cost)\n",
    "\n",
    "df.withColumn('round', round_cost)\\\n",
    "    .withColumn('floor', floor_cost)\\\n",
    "    .withColumn('ceil', ceil_cost)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date functions examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:27.373396Z",
     "start_time": "2022-01-26T10:58:27.057938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+-----------+\n",
      "|start_date|  end_date|days_between|start_month|\n",
      "+----------+----------+------------+-----------+\n",
      "|2015-01-01|2015-01-15|          14|          1|\n",
      "|2015-02-21|2015-03-08|          15|          2|\n",
      "+----------+----------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from pyspark.sql import functions as fn\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (date(2015, 1, 1), date(2015, 1, 15)),\n",
    "    (date(2015, 2, 21), date(2015, 3, 8)),\n",
    "], [\"start_date\", \"end_date\"])\n",
    "\n",
    "days_between = fn.datediff(df.end_date, df.start_date)\n",
    "start_month = fn.month(df.start_date)\n",
    "\n",
    "df.withColumn('days_between', days_between)\\\n",
    "    .withColumn('start_month', start_month)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:28.037428Z",
     "start_time": "2022-01-26T10:58:27.633093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------------+\n",
      "|first|second|               udf|\n",
      "+-----+------+------------------+\n",
      "|    1|     3|3 is bigger than 1|\n",
      "|    4|     2|4 is bigger than 2|\n",
      "+-----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "df = spark.createDataFrame([(1, 3), (4, 2)], [\"first\", \"second\"])\n",
    "\n",
    "def my_func(col_1, col_2):\n",
    "    if (col_1 > col_2):\n",
    "        return \"{} is bigger than {}\".format(col_1, col_2)\n",
    "    else:\n",
    "        return \"{} is bigger than {}\".format(col_2, col_1)\n",
    "\n",
    "my_udf = fn.udf(my_func, StringType())\n",
    "\n",
    "df.withColumn(\"udf\", my_udf(df['first'], df['second'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples using the Dataframe API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:35.398306Z",
     "start_time": "2022-01-26T10:58:34.710552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|prod_cat|  avg(prod_value)|\n",
      "+--------+-----------------+\n",
      "|keyboard|            59.99|\n",
      "|   mouse|43.32333333333333|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "products = spark.createDataFrame([\n",
    "    ('1', 'mouse', 'microsoft', 39.99),\n",
    "    ('2', 'mouse', 'microsoft', 59.99),\n",
    "    ('3', 'keyboard', 'microsoft', 59.99),\n",
    "    ('4', 'keyboard', 'logitech', 59.99),\n",
    "    ('5', 'mouse', 'logitech', 29.99),\n",
    "], ['prod_id', 'prod_cat', 'prod_brand', 'prod_value'])\n",
    "\n",
    "products.groupBy('prod_cat').avg('prod_value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:35.782623Z",
     "start_time": "2022-01-26T10:58:35.400724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|prod_cat|  avg(prod_value)|\n",
      "+--------+-----------------+\n",
      "|keyboard|            59.99|\n",
      "|   mouse|43.32333333333333|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products.groupBy('prod_cat').agg(fn.avg('prod_value')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:36.195471Z",
     "start_time": "2022-01-26T10:58:35.784780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+\n",
      "|prod_brand|prod_cat|avg(prod_value)|\n",
      "+----------+--------+---------------+\n",
      "| microsoft|   mouse|          49.99|\n",
      "|  logitech|keyboard|          59.99|\n",
      "| microsoft|keyboard|          59.99|\n",
      "|  logitech|   mouse|          29.99|\n",
      "+----------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "products.groupBy('prod_brand', 'prod_cat')\\\n",
    "    .agg(fn.avg('prod_value')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T07:49:40.612693Z",
     "start_time": "2022-11-26T07:49:40.457657Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:36.650354Z",
     "start_time": "2022-01-26T10:58:36.207985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---+-----+\n",
      "|prod_brand|average|sum|  min|\n",
      "+----------+-------+---+-----+\n",
      "|  logitech|   45.0| 90|29.99|\n",
      "| microsoft|   53.3|160|39.99|\n",
      "+----------+-------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "products.groupBy('prod_brand').agg(\n",
    "    fn.round(fn.avg('prod_value'), 1).alias('average'),\n",
    "    fn.ceil(fn.sum('prod_value')).alias('sum'),\n",
    "    fn.min('prod_value').alias('min')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:37.089099Z",
     "start_time": "2022-01-26T10:58:36.652842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+\n",
      "|prod_brand|average|  min|\n",
      "+----------+-------+-----+\n",
      "|  logitech|   45.0|29.99|\n",
      "| microsoft|   53.3|39.99|\n",
      "+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products.createOrReplaceTempView(\"products\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "prod_brand,\n",
    "round(avg(prod_value), 1) AS average,\n",
    "min(prod_value) AS min\n",
    "FROM products\n",
    "GROUP BY prod_brand\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Examples - Reading from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T07:29:14.654178Z",
     "start_time": "2022-11-26T07:29:12.449318Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df4 = spark.read.options(header='True',inferSchema='True') \\\n",
    "  .csv(\"netflix-titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "|show_id|   type|               title|            director|                cast|             country|        date_added|release_year|rating| duration|           listed_in|         description|\n",
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "|     s1|  Movie|Dick Johnson Is Dead|     Kirsten Johnson|                NULL|       United States|September 25, 2021|        2020| PG-13|   90 min|       Documentaries|As her father nea...|\n",
      "|     s2|TV Show|       Blood & Water|                NULL|Ama Qamata, Khosi...|        South Africa|September 24, 2021|        2021| TV-MA|2 Seasons|International TV ...|After crossing pa...|\n",
      "|     s3|TV Show|           Ganglands|     Julien Leclercq|Sami Bouajila, Tr...|                NULL|September 24, 2021|        2021| TV-MA| 1 Season|Crime TV Shows, I...|To protect his fa...|\n",
      "|     s4|TV Show|Jailbirds New Orl...|                NULL|                NULL|                NULL|September 24, 2021|        2021| TV-MA| 1 Season|Docuseries, Reali...|Feuds, flirtation...|\n",
      "|     s5|TV Show|        Kota Factory|                NULL|Mayur More, Jiten...|               India|September 24, 2021|        2021| TV-MA|2 Seasons|International TV ...|In a city of coac...|\n",
      "|     s6|TV Show|       Midnight Mass|       Mike Flanagan|Kate Siegel, Zach...|                NULL|September 24, 2021|        2021| TV-MA| 1 Season|TV Dramas, TV Hor...|The arrival of a ...|\n",
      "|     s7|  Movie|My Little Pony: A...|Robert Cullen, Jo...|Vanessa Hudgens, ...|                NULL|September 24, 2021|        2021|    PG|   91 min|Children & Family...|Equestria's divid...|\n",
      "|     s8|  Movie|             Sankofa|        Haile Gerima|Kofi Ghanaba, Oya...|United States, Gh...|September 24, 2021|        1993| TV-MA|  125 min|Dramas, Independe...|On a photo shoot ...|\n",
      "|     s9|TV Show|The Great British...|     Andy Devonshire|Mel Giedroyc, Sue...|      United Kingdom|September 24, 2021|        2021| TV-14|9 Seasons|British TV Shows,...|A talented batch ...|\n",
      "|    s10|  Movie|        The Starling|      Theodore Melfi|Melissa McCarthy,...|       United States|September 24, 2021|        2021| PG-13|  104 min|    Comedies, Dramas|A woman adjusting...|\n",
      "|    s11|TV Show|Vendetta: Truth, ...|                NULL|                NULL|                NULL|September 24, 2021|        2021| TV-MA| 1 Season|Crime TV Shows, D...|\"Sicily boasts a ...|\n",
      "|    s12|TV Show|    Bangkok Breaking|   Kongkiat Komesiri|Sukollawat Kanaro...|                NULL|September 23, 2021|        2021| TV-MA| 1 Season|Crime TV Shows, I...|Struggling to ear...|\n",
      "|    s13|  Movie|        Je Suis Karl| Christian Schwochow|Luna Wedler, Jann...|Germany, Czech Re...|September 23, 2021|        2021| TV-MA|  127 min|Dramas, Internati...|After most of her...|\n",
      "|    s14|  Movie|Confessions of an...|       Bruno Garotti|Klara Castanho, L...|                NULL|September 22, 2021|        2021| TV-PG|   91 min|Children & Family...|When the clever b...|\n",
      "|    s15|TV Show|Crime Stories: In...|                NULL|                NULL|                NULL|September 22, 2021|        2021| TV-MA| 1 Season|British TV Shows,...|Cameras following...|\n",
      "|    s16|TV Show|   Dear White People|                NULL|Logan Browning, B...|       United States|September 22, 2021|        2021| TV-MA|4 Seasons|TV Comedies, TV D...|\"Students of colo...|\n",
      "|    s17|  Movie|Europe's Most Dan...|Pedro de Echave G...|                NULL|                NULL|September 22, 2021|        2020| TV-MA|   67 min|Documentaries, In...|Declassified docu...|\n",
      "|    s18|TV Show|     Falsa identidad|                NULL|Luis Ernesto Fran...|              Mexico|September 22, 2021|        2020| TV-MA|2 Seasons|Crime TV Shows, S...|Strangers Diego a...|\n",
      "|    s19|  Movie|           Intrusion|          Adam Salky|Freida Pinto, Log...|                NULL|September 22, 2021|        2021| TV-14|   94 min|           Thrillers|After a deadly ho...|\n",
      "|    s20|TV Show|              Jaguar|                NULL|Blanca Suárez, Iv...|                NULL|September 22, 2021|        2021| TV-MA| 1 Season|International TV ...|In the 1960s, a H...|\n",
      "+-------+-------+--------------------+--------------------+--------------------+--------------------+------------------+------------+------+---------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"table\")\n",
    "query= \"SELECT * FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- Sort titles alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|                NULL|\n",
      "|                NULL|\n",
      "|\"Behind \"\"The Cov...|\n",
      "|\"Escape from the ...|\n",
      "|\"Gabriel \"\"Fluffy...|\n",
      "|\"Waiting for \"\"Su...|\n",
      "|              #Alive|\n",
      "|#AnneFrank - Para...|\n",
      "|   #FriendButMarried|\n",
      "| #FriendButMarried 2|\n",
      "|               #Roxy|\n",
      "|           #Rucker50|\n",
      "|             #Selfie|\n",
      "|          #Selfie 69|\n",
      "|            #blackAF|\n",
      "|    #cats_the_mewvie|\n",
      "|        #realityhigh|\n",
      "|                 '76|\n",
      "|                 '89|\n",
      "|            (T)ERROR|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"table\")\n",
    "query= \"SELECT title FROM table ORDER BY title ASC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many movies were released in 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|movie_count|\n",
      "+-----------+\n",
      "|        765|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"table\")\n",
    "query= \"SELECT count(type) AS movie_count FROM table WHERE type= 'Movie' AND release_year= 2018\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- which country produced the most movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|             country|movie_count|\n",
      "+--------------------+-----------+\n",
      "|       United States|       2047|\n",
      "|               India|        893|\n",
      "|                NULL|        440|\n",
      "|      United Kingdom|        206|\n",
      "|              Canada|        122|\n",
      "|               Spain|         97|\n",
      "|               Egypt|         92|\n",
      "|             Nigeria|         85|\n",
      "|           Indonesia|         77|\n",
      "|              Turkey|         76|\n",
      "|               Japan|         76|\n",
      "|              France|         74|\n",
      "|         Philippines|         73|\n",
      "|              Mexico|         70|\n",
      "|United Kingdom, U...|         63|\n",
      "|United States, Ca...|         51|\n",
      "|              Brazil|         50|\n",
      "|           Hong Kong|         50|\n",
      "|             Germany|         47|\n",
      "|         South Korea|         41|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"table\")\n",
    "query= \"SELECT country, count(title) AS movie_count FROM table WHERE type= 'Movie' GROUP BY country ORDER BY movie_count DESC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many tv shows lasted 1 season\n",
    "- which year had the least number of tv shows produced\n",
    "- when was the earliest release date for a movie in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|count|\n",
      "+-----+\n",
      "| 1791|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"table\")\n",
    "query= \"SELECT count(*) AS count FROM table WHERE type='TV Show'AND duration= '1 Season'\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+\n",
      "|     release_year|tv_show_count|\n",
      "+-----------------+-------------+\n",
      "|             1967|            1|\n",
      "|             1972|            1|\n",
      "|             1977|            1|\n",
      "|December 15, 2020|            1|\n",
      "|             1981|            1|\n",
      "|             1974|            1|\n",
      "|             1946|            1|\n",
      "|             1989|            1|\n",
      "|             1963|            1|\n",
      "|             1925|            1|\n",
      "|    Nse Ikpe-Etim|            1|\n",
      "|      Jade Eshete|            1|\n",
      "|             1985|            1|\n",
      "|             1979|            1|\n",
      "|             1991|            1|\n",
      "|             1945|            1|\n",
      "|             1988|            2|\n",
      "|             1995|            2|\n",
      "|             1994|            2|\n",
      "|             1986|            2|\n",
      "+-----------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"table\")\n",
    "query= \"SELECT release_year, COUNT(title) AS tv_show_count FROM table WHERE type= 'TV Show' GROUP BY release_year ORDER BY tv_show_count ASC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     release_year|\n",
      "+-----------------+\n",
      "|     Ted Ferguson|\n",
      "|             1987|\n",
      "|             1956|\n",
      "|             2016|\n",
      "|             2020|\n",
      "|             2012|\n",
      "|             1958|\n",
      "|           40 min|\n",
      "|             1943|\n",
      "|             1972|\n",
      "| Marquell Manning|\n",
      "|             1988|\n",
      "|             2019|\n",
      "|             2017|\n",
      "|             1977|\n",
      "|             2014|\n",
      "|             1971|\n",
      "|             1984|\n",
      "|             2013|\n",
      "|             1982|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"table\")\n",
    "query= \"SELECT DISTINCT (release_year) FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- show_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- director: string (nullable = true)\n",
      " |-- cast: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- date_added: string (nullable = true)\n",
      " |-- release_year: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- duration: string (nullable = true)\n",
      " |-- listed_in: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|     release_year|\n",
      "+-----------------+\n",
      "|     Ted Ferguson|\n",
      "|             1987|\n",
      "|             1956|\n",
      "|             2016|\n",
      "|             2020|\n",
      "|             2012|\n",
      "|             1958|\n",
      "|           40 min|\n",
      "|             1943|\n",
      "|             1972|\n",
      "| Marquell Manning|\n",
      "|             1988|\n",
      "|             2019|\n",
      "|             2017|\n",
      "|             1977|\n",
      "|             2014|\n",
      "|             1971|\n",
      "|             1984|\n",
      "|             2013|\n",
      "|             1982|\n",
      "|             2005|\n",
      "|             2000|\n",
      "|             1965|\n",
      "|             1962|\n",
      "|             1954|\n",
      "|   Charles Rocket|\n",
      "|December 15, 2020|\n",
      "|             1981|\n",
      "|   Peter Ferriero|\n",
      "|             1978|\n",
      "|             1974|\n",
      "|             2002|\n",
      "|             1959|\n",
      "|       Paul Sambo|\n",
      "|             2018|\n",
      "|             2009|\n",
      "|    United States|\n",
      "|             1995|\n",
      "|             1964|\n",
      "|          Dr. Dre|\n",
      "|             1946|\n",
      "|             2006|\n",
      "|       Nick Kroll|\n",
      "|             1976|\n",
      "|     Imanol Arias|\n",
      "|             1942|\n",
      "|             1947|\n",
      "|             1967|\n",
      "|             1968|\n",
      "|             2004|\n",
      "+-----------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.select(\"release_year\").distinct().show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|release_year|\n",
      "+------------+\n",
      "|        1942|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.createOrReplaceTempView(\"table\")\n",
    "query= \"SELECT DISTINCT(release_year) FROM table WHERE release_year IS NOT NULL AND release_year RLIKE '^[0-9]+$' AND type= 'Movie' ORDER BY CAST(release_year AS INT) ASC LIMIT 1\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
