{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark II - Dataframes and SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T07:29:05.335514Z",
     "start_time": "2022-11-26T07:29:05.327050Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "    .builder\n",
    "    .appName(\"Spark SQL Course\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-04T13:26:29.707124Z",
     "start_time": "2020-02-04T13:26:29.703404Z"
    }
   },
   "source": [
    "# `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:10.542875Z",
     "start_time": "2022-11-26T05:56:10.531942Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "row1 = Row(name=\"John\", age=21)\n",
    "row2 = Row(name=\"James\", age=32)\n",
    "row3 = Row(name=\"Jane\", age=18)\n",
    "row1['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:24.857874Z",
     "start_time": "2022-11-26T05:56:24.806632Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([row1, row2, row3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(name='John', age=21), Row(name='James', age=32), Row(name='Jane', age=18)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:25.579042Z",
     "start_time": "2022-11-26T05:56:25.571707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:27.694750Z",
     "start_time": "2022-11-26T05:56:26.310055Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| name|age|\n",
      "+-----+---+\n",
      "| John| 21|\n",
      "|James| 32|\n",
      "| Jane| 18|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:28.671432Z",
     "start_time": "2022-11-26T05:56:28.639892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8) MapPartitionsRDD[10] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[9] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  SQLExecutionRDD[8] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[7] at javaToPython at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[4] at applySchemaToPythonRDD at NativeMethodAccessorImpl.java:0 []\n",
      " |  MapPartitionsRDD[3] at map at SerDeUtil.scala:137 []\n",
      " |  MapPartitionsRDD[2] at mapPartitions at SerDeUtil.scala:184 []\n",
      " |  PythonRDD[1] at RDD at PythonRDD.scala:53 []\n",
      " |  ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262 []\n"
     ]
    }
   ],
   "source": [
    "print(df.rdd.toDebugString().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:56:31.842753Z",
     "start_time": "2022-11-26T05:56:31.833146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:55:33.939023Z",
     "start_time": "2022-11-26T05:55:33.388845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 21|  male|\n",
      "| James| 25|female|\n",
      "|Albert| 46|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rows = [\n",
    "    Row(name=\"John\", age=21, gender=\"male\"),\n",
    "    Row(name=\"James\", age=25, gender=\"female\"),\n",
    "    Row(name=\"Albert\", age=46, gender=\"male\")\n",
    "]\n",
    "df = spark.createDataFrame(rows)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T05:55:38.708168Z",
     "start_time": "2022-11-26T05:55:38.295622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 21|  male|\n",
      "| James| 25|female|\n",
      "|Albert| 46|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"name\", \"age\", \"gender\"]\n",
    "rows = [\n",
    "    [\"John\", 21, \"male\"],\n",
    "    [\"James\", 25, \"female\"],\n",
    "    [\"Albert\", 46, \"male\"]\n",
    "]\n",
    "df = spark.createDataFrame(rows, column_names)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:19.074335Z",
     "start_time": "2022-01-26T10:58:19.068088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:37:24.358575Z",
     "start_time": "2022-11-26T06:37:16.489467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 21|  male|\n",
      "| James| 25|female|\n",
      "|Albert| 46|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"name\", \"age\", \"gender\"]\n",
    "rdd = sc.parallelize([\n",
    "    (\"John\", 21, \"male\"),\n",
    "    (\"James\", 25, \"female\"),\n",
    "    (\"Albert\", 46, \"male\")\n",
    "])\n",
    "df = spark.createDataFrame(rdd, column_names)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe to rdd and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:37:41.958143Z",
     "start_time": "2022-11-26T06:37:41.952273Z"
    }
   },
   "outputs": [],
   "source": [
    "rdd2 = df.rdd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:42:38.623506Z",
     "start_time": "2022-11-26T06:42:38.617300Z"
    }
   },
   "outputs": [],
   "source": [
    "rdd3 = rdd2.map(lambda x: [x[0],x[1]+10,x[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:42:39.959294Z",
     "start_time": "2022-11-26T06:42:39.391647Z"
    }
   },
   "outputs": [],
   "source": [
    "df = rdd3.toDF([\"name\",\"age\",\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:42:46.156497Z",
     "start_time": "2022-11-26T06:42:45.826816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+------+\n",
      "|  name|age|gender|\n",
      "+------+---+------+\n",
      "|  John| 31|  male|\n",
      "| James| 35|female|\n",
      "|Albert| 56|  male|\n",
      "+------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:19.850578Z",
     "start_time": "2022-01-26T10:58:19.843835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(name,StringType,true),StructField(age,LongType,true),StructField(gender,StringType,true)))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T06:43:16.125207Z",
     "start_time": "2022-11-26T06:43:16.101139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:19.860631Z",
     "start_time": "2022-01-26T10:58:19.854012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.types.StructType"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:20.199419Z",
     "start_time": "2022-01-26T10:58:19.863528Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      "\n",
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True)\n",
    "])\n",
    "rows = [(\"John\", 21, \"male\")]\n",
    "df = spark.createDataFrame(rows, schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:20.882311Z",
     "start_time": "2022-01-26T10:58:20.201993Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|John| 21|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"name\", \"age\", \"gender\"]\n",
    "rows = [\n",
    "    [\"John\", 21, \"male\"],\n",
    "    [\"Jane\", 25, \"female\"]\n",
    "]\n",
    "df = spark.createDataFrame(rows, column_names)\n",
    "\n",
    "# Create a temporary view from the DataFrame\n",
    "df.createOrReplaceTempView(\"new_view\")\n",
    "\n",
    "# Apply the query\n",
    "query = \"SELECT name, age FROM new_view WHERE gender='male'\"\n",
    "men_df = spark.sql(query)\n",
    "men_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SELECT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:21.162623Z",
     "start_time": "2022-01-26T10:58:20.884802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|John| 21|\n",
      "|Jane| 25|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT name, age FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:21.388097Z",
     "start_time": "2022-01-26T10:58:21.164840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|name|age|\n",
      "+----+---+\n",
      "|John| 21|\n",
      "|Jane| 25|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"name\", \"age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `WHERE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:21.704402Z",
     "start_time": "2022-01-26T10:58:21.402155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT * FROM table WHERE age > 21\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:21.924501Z",
     "start_time": "2022-01-26T10:58:21.706741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(\"age > 21\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:22.377417Z",
     "start_time": "2022-01-26T10:58:21.926708Z"
    }
   },
   "source": [
    "# Alternatively:\n",
    "df.where(df['age'] > 21).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:22.566385Z",
     "start_time": "2022-01-26T10:58:22.380036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.age > 21).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:22.837136Z",
     "start_time": "2022-01-26T10:58:22.569324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").where(\"age > 21\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LIMIT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:23.315363Z",
     "start_time": "2022-01-26T10:58:22.842106Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = query = \"SELECT * FROM table LIMIT 1\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:23.522646Z",
     "start_time": "2022-01-26T10:58:23.318694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:23.778517Z",
     "start_time": "2022-01-26T10:58:23.525281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").limit(1).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ORDER BY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:24.190838Z",
     "start_time": "2022-01-26T10:58:23.781166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT * FROM table ORDER BY name ASC\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:24.368069Z",
     "start_time": "2022-01-26T10:58:24.193899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|gender|\n",
      "+----+---+------+\n",
      "|Jane| 25|female|\n",
      "|John| 21|  male|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df.name.asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `ALIAS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:24.643668Z",
     "start_time": "2022-01-26T10:58:24.370758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|   sex|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT name, age, gender AS sex FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:24.858104Z",
     "start_time": "2022-01-26T10:58:24.646119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+\n",
      "|name|age|   sex|\n",
      "+----+---+------+\n",
      "|John| 21|  male|\n",
      "|Jane| 25|female|\n",
      "+----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, df.age, df.gender.alias('sex')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CAST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:25.072286Z",
     "start_time": "2022-01-26T10:58:24.860474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|age_f|\n",
      "+----+-----+\n",
      "|John| 21.0|\n",
      "|Jane| 25.0|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT name, cast(age AS float) AS age_f FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:25.384433Z",
     "start_time": "2022-01-26T10:58:25.074523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|age_f|\n",
      "+----+-----+\n",
      "|John| 21.0|\n",
      "|Jane| 25.0|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.name, df.age.cast(\"float\").alias(\"age_f\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:25.648155Z",
     "start_time": "2022-01-26T10:58:25.386952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|age_f|\n",
      "+----+-----+\n",
      "|John| 21.0|\n",
      "|Jane| 25.0|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_age_col = df.age.cast(\"float\").alias(\"age_f\")\n",
    "df.select(df.name, new_age_col).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:25.931495Z",
     "start_time": "2022-01-26T10:58:25.651283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+----------+\n",
      "|name|age|gender|age_months|\n",
      "+----+---+------+----------+\n",
      "|John| 21|  male|       252|\n",
      "|Jane| 25|female|       300|\n",
      "+----+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"table\")\n",
    "query = \"SELECT *, 12*age AS age_months FROM table\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:26.195480Z",
     "start_time": "2022-01-26T10:58:25.933620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+----------+\n",
      "|name|age|gender|age_months|\n",
      "+----+---+------+----------+\n",
      "|John| 21|  male|       252|\n",
      "|Jane| 25|female|       300|\n",
      "+----+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"age_months\", df.age * 12).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:26.422122Z",
     "start_time": "2022-01-26T10:58:26.197759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+------+----------+\n",
      "|name|age|gender|age_months|\n",
      "+----+---+------+----------+\n",
      "|John| 21|  male|       252|\n",
      "|Jane| 25|female|       300|\n",
      "+----+---+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\", (df.age * 12).alias(\"age_months\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric functions examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:26.748718Z",
     "start_time": "2022-01-26T10:58:26.425451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+-----+----+\n",
      "|  brand|cost|round|floor|ceil|\n",
      "+-------+----+-----+-----+----+\n",
      "|garnier|3.49|  3.5|    3|   4|\n",
      "| elseve|2.71|  2.7|    2|   3|\n",
      "+-------+----+-----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "columns = [\"brand\", \"cost\"]\n",
    "df = spark.createDataFrame([\n",
    "    (\"garnier\", 3.49),\n",
    "    (\"elseve\", 2.71)\n",
    "], columns)\n",
    "\n",
    "round_cost = fn.round(df.cost, 1)\n",
    "floor_cost = fn.floor(df.cost)\n",
    "ceil_cost = fn.ceil(df.cost)\n",
    "\n",
    "df.withColumn('round', round_cost)\\\n",
    "    .withColumn('floor', floor_cost)\\\n",
    "    .withColumn('ceil', ceil_cost)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date functions examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:27.373396Z",
     "start_time": "2022-01-26T10:58:27.057938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------+-----------+\n",
      "|start_date|  end_date|days_between|start_month|\n",
      "+----------+----------+------------+-----------+\n",
      "|2015-01-01|2015-01-15|          14|          1|\n",
      "|2015-02-21|2015-03-08|          15|          2|\n",
      "+----------+----------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from pyspark.sql import functions as fn\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (date(2015, 1, 1), date(2015, 1, 15)),\n",
    "    (date(2015, 2, 21), date(2015, 3, 8)),\n",
    "], [\"start_date\", \"end_date\"])\n",
    "\n",
    "days_between = fn.datediff(df.end_date, df.start_date)\n",
    "start_month = fn.month(df.start_date)\n",
    "\n",
    "df.withColumn('days_between', days_between)\\\n",
    "    .withColumn('start_month', start_month)\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:28.037428Z",
     "start_time": "2022-01-26T10:58:27.633093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------------+\n",
      "|first|second|               udf|\n",
      "+-----+------+------------------+\n",
      "|    1|     3|3 is bigger than 1|\n",
      "|    4|     2|4 is bigger than 2|\n",
      "+-----+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "df = spark.createDataFrame([(1, 3), (4, 2)], [\"first\", \"second\"])\n",
    "\n",
    "def my_func(col_1, col_2):\n",
    "    if (col_1 > col_2):\n",
    "        return \"{} is bigger than {}\".format(col_1, col_2)\n",
    "    else:\n",
    "        return \"{} is bigger than {}\".format(col_2, col_1)\n",
    "\n",
    "my_udf = fn.udf(my_func, StringType())\n",
    "\n",
    "df.withColumn(\"udf\", my_udf(df['first'], df['second'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agregations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples using the Dataframe API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:35.398306Z",
     "start_time": "2022-01-26T10:58:34.710552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|prod_cat|  avg(prod_value)|\n",
      "+--------+-----------------+\n",
      "|keyboard|            59.99|\n",
      "|   mouse|43.32333333333333|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "products = spark.createDataFrame([\n",
    "    ('1', 'mouse', 'microsoft', 39.99),\n",
    "    ('2', 'mouse', 'microsoft', 59.99),\n",
    "    ('3', 'keyboard', 'microsoft', 59.99),\n",
    "    ('4', 'keyboard', 'logitech', 59.99),\n",
    "    ('5', 'mouse', 'logitech', 29.99),\n",
    "], ['prod_id', 'prod_cat', 'prod_brand', 'prod_value'])\n",
    "\n",
    "products.groupBy('prod_cat').avg('prod_value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:35.782623Z",
     "start_time": "2022-01-26T10:58:35.400724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|prod_cat|  avg(prod_value)|\n",
      "+--------+-----------------+\n",
      "|keyboard|            59.99|\n",
      "|   mouse|43.32333333333333|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products.groupBy('prod_cat').agg(fn.avg('prod_value')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:36.195471Z",
     "start_time": "2022-01-26T10:58:35.784780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+---------------+\n",
      "|prod_brand|prod_cat|avg(prod_value)|\n",
      "+----------+--------+---------------+\n",
      "| microsoft|   mouse|          49.99|\n",
      "|  logitech|keyboard|          59.99|\n",
      "| microsoft|keyboard|          59.99|\n",
      "|  logitech|   mouse|          29.99|\n",
      "+----------+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "products.groupBy('prod_brand', 'prod_cat')\\\n",
    "    .agg(fn.avg('prod_value')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T07:49:40.612693Z",
     "start_time": "2022-11-26T07:49:40.457657Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:36.650354Z",
     "start_time": "2022-01-26T10:58:36.207985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+---+-----+\n",
      "|prod_brand|average|sum|  min|\n",
      "+----------+-------+---+-----+\n",
      "|  logitech|   45.0| 90|29.99|\n",
      "| microsoft|   53.3|160|39.99|\n",
      "+----------+-------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "products.groupBy('prod_brand').agg(\n",
    "    fn.round(fn.avg('prod_value'), 1).alias('average'),\n",
    "    fn.ceil(fn.sum('prod_value')).alias('sum'),\n",
    "    fn.min('prod_value').alias('min')\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-26T10:58:37.089099Z",
     "start_time": "2022-01-26T10:58:36.652842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-----+\n",
      "|prod_brand|average|  min|\n",
      "+----------+-------+-----+\n",
      "|  logitech|   45.0|29.99|\n",
      "| microsoft|   53.3|39.99|\n",
      "+----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "products.createOrReplaceTempView(\"products\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "prod_brand,\n",
    "round(avg(prod_value), 1) AS average,\n",
    "min(prod_value) AS min\n",
    "FROM products\n",
    "GROUP BY prod_brand\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Examples - Reading from a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-26T07:29:14.654178Z",
     "start_time": "2022-11-26T07:29:12.449318Z"
    }
   },
   "outputs": [],
   "source": [
    "df4 = spark.read.options(header='True',inferSchema='True') \\\n",
    "  .csv(\"netflix-titles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sort titles alphabetically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many movies were released in 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- which country produced the most movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practice - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- How many tv shows lasted 1 season\n",
    "- which year had the least number of tv shows produced\n",
    "- when was the earliest release date for a movie in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
